{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf  # For tf.data and preprocessing only.\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras import layers\n",
    "# from keras import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage import io  # for reading TIFF images\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, cohen_kappa_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "import rasterio\n",
    "import h5py\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "input_shape = (90, 90, 15)\n",
    "\n",
    "patch_size = (5, 5)  # 2-by-2 sized patches\n",
    "dropout_rate = 0.03  # Dropout rate\n",
    "num_heads = 64  # Attention heads\n",
    "embed_dim = 128  # Embedding dimension\n",
    "num_mlp = 1024  # MLP layer size\n",
    "# Convert embedded patches to query, key, and values with a learnable additive\n",
    "# value\n",
    "qkv_bias = True\n",
    "window_size = 2  # Size of attention window\n",
    "shift_size = 0  # Size of shifting window\n",
    "image_dimension = 90  # Initial image size\n",
    "\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "num_epochs = 140\n",
    "weight_decay = 0.001\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired number of patches\n",
    "desired_num_patches = 15000\n",
    "\n",
    "# Your data directories\n",
    "optic_images_dir = 'Sentinel-2-patches/'\n",
    "sar_images_dir = 'Sentinel-1-patches/' \n",
    "agb_maps_dir = ''\n",
    "\n",
    "# Get the list of file names in the directories without sorting\n",
    "agb_map_files = os.listdir(agb_maps_dir)\n",
    "optic_image_files = os.listdir(optic_images_dir)\n",
    "sar_image_files = os.listdir(sar_images_dir)\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "agb_values_list = []\n",
    "\n",
    "# Loop through each patch with tqdm for progress bars\n",
    "# Loop through each patch with tqdm for progress bars\n",
    "for i in tqdm(range(desired_num_patches), desc='Loading Patches'):\n",
    "    # Get file names for the current index\n",
    "    optic_file = optic_image_files[i]\n",
    "    sar_file = sar_image_files[i]\n",
    "    agb_file = agb_map_files[i]\n",
    "    # Load images\n",
    "    optic_image = io.imread(os.path.join(optic_images_dir, optic_file))\n",
    "    sar_image = io.imread(os.path.join(sar_images_dir, sar_file))\n",
    "    agb_map = io.imread(os.path.join(agb_maps_dir, agb_file))\n",
    "\n",
    "    # Save AGB values as a NumPy array\n",
    "    agb_values_list.append(agb_map.flatten())\n",
    "\n",
    "    # Ensure optic image has 13 bands\n",
    "    if optic_image.shape[-1] == 13:\n",
    "        x_train = optic_image\n",
    "    else:\n",
    "        raise ValueError(\"Optic image should have 13 bands. Found: {}\".format(optic_image.shape[-1]))\n",
    "\n",
    "    # Check if SAR image has 2 bands\n",
    "    if len(sar_image.shape) == 2:\n",
    "        # Expand dimensions to make it 3D\n",
    "        sar_image = np.stack([sar_image, sar_image], axis=-1)\n",
    "\n",
    "    # Normalize the data using min-max scaling\n",
    "    optic_image_normalized = (optic_image - np.min(optic_image)) / (np.max(optic_image) - np.min(optic_image))\n",
    "    sar_image_normalized = (sar_image - np.min(sar_image)) / (np.max(sar_image) - np.min(sar_image))\n",
    "\n",
    "    # Concatenate optic and SAR images\n",
    "    x_train = np.concatenate([optic_image_normalized, sar_image_normalized], axis=-1)\n",
    "\n",
    "    x_train_list.append(x_train)\n",
    "\n",
    "    # Break the loop when desired_num_patches is reached\n",
    "    if len(x_train_list) >= desired_num_patches:\n",
    "        break\n",
    "\n",
    "# Combine all patches into single arrays\n",
    "x_data = np.stack(x_train_list)\n",
    "agb_values = np.concatenate(agb_values_list)\n",
    "\n",
    "# Normalize AGB values using min-max scaling\n",
    "min_agb = np.min(agb_values)\n",
    "max_agb = np.max(agb_values)\n",
    "agb_scaled = (agb_values - min_agb) / (max_agb - min_agb)\n",
    "\n",
    "# Reshape scaled AGB values for compatibility with the model\n",
    "agb_normalized = np.expand_dims(agb_scaled, axis=-1)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, agb_normalized, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76684e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x,\n",
    "        (\n",
    "            -1,\n",
    "            patch_num_y,\n",
    "            window_size,\n",
    "            patch_num_x,\n",
    "            window_size,\n",
    "            channels,\n",
    "        ),\n",
    "    )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        (\n",
    "            -1,\n",
    "            patch_num_y,\n",
    "            patch_num_x,\n",
    "            window_size,\n",
    "            window_size,\n",
    "            channels,\n",
    "        ),\n",
    "    )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, (-1, height, width, channels))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        window_size,\n",
    "        num_heads,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
    "            2 * self.window_size[1] - 1\n",
    "        )\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(num_window_elements, self.num_heads),\n",
    "            initializer=keras.initializers.Zeros(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        # self.relative_position_index = keras.Variable(\n",
    "         #   initializer=relative_position_index,\n",
    "        #    shape=relative_position_index.shape,\n",
    "         #   dtype=\"int\",\n",
    "        #    trainable=False,\n",
    "        #)\n",
    "\n",
    "\n",
    "# Define self.relative_position_index using tf.Variable\n",
    "        self.relative_position_index = tf.Variable(\n",
    "                initial_value=relative_position_index,\n",
    "                trainable=False,\n",
    "                dtype=tf.int32  # Set the data type to int32\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, (2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, (0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table,\n",
    "            relative_position_index_flat,\n",
    "            axis=0,\n",
    "        )\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias,\n",
    "            (num_window_elements, num_window_elements, -1),\n",
    "        )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, (2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0),\n",
    "                \"float32\",\n",
    "            )\n",
    "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
    "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, (0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = layers.Dropout(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, [-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(\n",
    "                initial_value=attn_mask,\n",
    "\n",
    "                dtype=attn_mask.dtype,\n",
    "                trainable=False,\n",
    "            )\n",
    "\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, (-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, (-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows,\n",
    "            (-1, self.window_size, self.window_size, channels),\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, (-1, height * width, channels))\n",
    "        x = self.drop_path(x, training=training)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "      config = super().get_config()\n",
    "      config.update({\n",
    "        \"dim\": self.dim,\n",
    "        \"num_patch\": self.num_patch,\n",
    "        \"num_heads\": self.num_heads,\n",
    "        \"window_size\": self.window_size,\n",
    "        \"shift_size\": self.shift_size,\n",
    "        \"num_mlp\": self.num_mlp,\n",
    "        \n",
    "      })\n",
    "      return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using tf ops since it is only used in tf.data.\n",
    "def patch_extract(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
    "        strides=(1, patch_size[0], patch_size[1], 1),\n",
    "        rates=(1, 1, 1, 1),\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patch_dim = patches.shape[-1]\n",
    "    patch_num = patches.shape[1]\n",
    "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
    "\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start=0, limit=self.num_patch)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_patch': self.num_patch,\n",
    "            'embed_dim': self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class PatchMerging(keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs) \n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.shape\n",
    "        x = tf.reshape(x, (-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
    "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)\n",
    "    def get_config(self):\n",
    "          config = super().get_config()\n",
    "          config.update({\n",
    "            'num_patch': self.num_patch,\n",
    "            'embed_dim': self.embed_dim,\n",
    "            \n",
    "          })\n",
    "          return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06576ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment(x):\n",
    "    x = tf.image.random_crop(x, size=(image_dimension, image_dimension, 15))\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(lambda x, y: (augment(x), y))\n",
    "    .batch(batch_size=batch_size)\n",
    "    .map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset_val = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    .batch(batch_size=batch_size)\n",
    "    .map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset_test = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(batch_size=batch_size)\n",
    "    .map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(dataset, 'dataset_train')\n",
    "tf.data.experimental.save(dataset_val, 'dataset_val')\n",
    "tf.data.experimental.save(dataset_test, 'dataset_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.experimental.load('dataset_train')\n",
    "dataset_val = tf.data.experimental.load('dataset_val')\n",
    "dataset_test = tf.data.experimental.load('dataset_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(324, 375))\n",
    "x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(input)\n",
    "x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=0,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=shift_size,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "output = layers.Dense(num_classes, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ded1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SaveBestModel(Callback):\n",
    "    def __init__(self, filepath, monitor='val_mae', mode='auto', save_best_only=True):\n",
    "        super(SaveBestModel, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_value = None\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.monitor_op = lambda a, b: a < b\n",
    "            self.best_value = float('inf')\n",
    "        elif self.mode == 'max':\n",
    "            self.monitor_op = lambda a, b: a > b\n",
    "            self.best_value = float('-inf')\n",
    "        else:\n",
    "            self.monitor_op = lambda a, b: a == b\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is None:\n",
    "            print(f\"WARNING: Can't find {self.monitor} in logs. Model not saved.\")\n",
    "            return\n",
    "\n",
    "        if self.monitor_op(current_value, self.best_value):\n",
    "            if self.save_best_only:\n",
    "                print(f\"\\nEpoch {epoch + 1}: {self.monitor} improved from {self.best_value} to {current_value}, saving model to {self.filepath}\")\n",
    "                self.model.save(self.filepath, overwrite=True)\n",
    "                self.best_value = current_value\n",
    "            else:\n",
    "                print(f\"\\nEpoch {epoch + 1}: {self.monitor} improved from {self.best_value} to {current_value}, saving model to {self.filepath}\")\n",
    "                self.model.save(self.filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168623aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = keras.Model(input, output)\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "\n",
    "\n",
    "checkpoint_filepath = 'best_model.keras'\n",
    "checkpoint_callback = SaveBestModel(filepath=checkpoint_filepath, monitor='val_mae',\n",
    "                                     mode='min', save_best_only=True)\n",
    "\n",
    "# Training loop\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = keras.models.load_model('best_model (2).keras', custom_objects={'SwinTransformer': SwinTransformer,\n",
    "                                                                            'WindowAttention': WindowAttention,\n",
    "                                                                            'PatchEmbedding': PatchEmbedding,\n",
    "                                                                            'PatchMerging': PatchMerging})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(dataset_test)\n",
    "y_pred = y_pred1 * (max_agb - min_agb) + min_agb\n",
    "y_test2 = y_test * (max_agb - min_agb) + min_agb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67644f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "y_test2_flat = y_test2.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calculate R^2\n",
    "r2 = r2_score(y_test2_flat, y_pred_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training data\n",
    "y_train_pred = model.predict(dataset_train)\n",
    "y_train_pred = y_train_pred * (max_agb - min_agb) + min_agb  # Denormalize predictions\n",
    "y_train_denormalized = y_train * (max_agb - min_agb) + min_agb  # Denormalize true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47264b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# # Flatten the arrays\n",
    "y_train_denormalized_flat = y_train_denormalized.flatten()\n",
    "y_train_pred_flat = y_train_pred.flatten()\n",
    "\n",
    "# Calculate metrics for training data\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_denormalized_flat, y_train_pred_flat))\n",
    "train_mae = mean_absolute_error(y_train_denormalized_flat, y_train_pred_flat)\n",
    "train_r2 = r2_score(y_train_denormalized_flat, y_train_pred_flat)\n",
    "\n",
    "# Flatten the arrays for test data as well\n",
    "y_test_denormalized_flat = y_test2.flatten()\n",
    "y_test_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_denormalized_flat, y_test_pred_flat))\n",
    "test_mae = mean_absolute_error(y_test_denormalized_flat, y_test_pred_flat)\n",
    "test_r2 = r2_score(y_test_denormalized_flat, y_test_pred_flat)\n",
    "\n",
    "#Print or use the metrics as needed\n",
    "print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Train MAE: {train_mae:.4f}\")\n",
    "print(f\"Train R2: {train_r2:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test R2: {test_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
